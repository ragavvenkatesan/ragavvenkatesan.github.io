
<!-- CVPR 19-->		

<div class="item mix cpaper" data-year="2019">
		<div class="pubmain">
		<div class="pubassets">
			<a href="#" class="pubcollapse">
				<i class="icon-plus"></i>
			</a>
			<a href="{{ site.url }}/publications/2019/bib/cvpr_19.bib" class="tooltips" title="Bibtex" target="_blank">
				<i class="icon-book"></i>
			</a>
		</div>
		CVPR 2019
		<h4 class="pubtitle">d-SNE: Domain Adaptation using Stochastic Neighborhood Embedding</h4>
		<div class="pubauthor"><a traget="_blank" href="https://www.linkedin.com/in/shownx/">Xiang Xu</a>,
			<a traget="_blank" href="https://www.linkedin.com/in/xiongzhou/">Xiong Zhou</a>,
			<strong>Ragav Venkatesan</strong>,
			<a traget="_blank" href="https://www.linkedin.com/in/gurumurthy-swaminathan-b395062/">Gurumurthy Swaminathan</a>,			
			<a traget="_blank" href="https://www.linkedin.com/in/orchidmajumder/">Orchid Majumdar</a>							
		</div>
		<div class="pubcite"><span class="label label-warning">Conference Papers</span>
				IEEE Conference on Computer Vision and Pattern Recognition, Long Beach, California, USA, 2019. [ORAL with 5.5% acceptance rate.]</div>
		
		</div>
		<div class="pubdetails">
		<h4>Abstract</h4>
		<p>		On the one hand, deep neural networks are effective in
				learning large datasets. On the other, they are inefficient
				with their data usage. They often require copious amount
				of labeled-data to train their scads of parameters. Training larger and deeper networks is hard without appropriate regularization, particularly while using a small dataset.
				Laterally, collecting well-annotated data is expensive, timeconsuming and often infeasible. A popular way to regularize these networks is to simply train the network with
				more data from an alternate representative dataset. This
				can lead to adverse effects if the statistics of the representative dataset are dissimilar to our target. This predicament
				is due to the problem of domain shift. Data from a shifted
				domain might not produce bespoke features when a feature
				extractor from the representative domain is used.</p>

		<p>		Several techniques of domain adaptation have been proposed in the past to solve this problem. In this paper,
				we propose a new technique (d-SNE) of domain adaptation that cleverly uses stochastic neighborhood embedding
				techniques and a novel modified-Hausdorff distance. The
				proposed technique is learnable end-to-end and is therefore, ideally suited to train neural networks. Extensive experiments demonstrate that d-SNE outperforms the current
				states-of-the-art and is robust to the variances in different
				datasets, even in the one-shot and semi-supervised learning
				settings. d-SNE also demonstrates the ability to generalize
				to multiple domains concurrently</p></div>
		</div>
		
		<!-- End of One Item -->







<!-- Features Book Chapter -->		

<div class="item mix book" data-year="2018">
	<div class="pubmain">
		<div class="pubassets">
		
			<a href="#" class="pubcollapse">
			<i class="icon-plus"></i>
			</a>
			
			<a href="https://www.amazon.com/Engineering-Learning-Analytics-Knowledge-Discovery/dp/1138744387/ref=sr_1_2?ie=UTF8&qid=1529209592&sr=8-2&keywords=Feature+Engineering+for+Machine+Learning+and++Data+Analytic" class="tooltips" title="book website" target="_blank">
			<i class="icon-external-link"></i>
			</a>

		</div>
		
		<h4 class="pubtitle">Feature Engineering for Machine Learning and Data Analytics. - Chapter 3.</h4>
		<div class="pubauthor"><strong>Ragav Venkatesan</strong>, Parag Shridhar Chandakkar, <a target="_blank" href="http://www.public.asu.edu/~bli24/">Baoxin Li</a></div>
		<div class="pubcite"><span class="label label-primary">Book</span>Chapman & Hall/CRC Press.</div>
		
		
	</div>
	<div class="pubdetails">
		<h4>About the book</h4>
		<p>Feature engineering plays a vital role in big data analytics. Machine learning and data mining algorithms cannot work without data. Little can be achieved if there are few features to represent the underlying data objects, and the quality of results of those algorithms largely depends on the quality of the available features. Feature Engineering for Machine Learning and Data Analytics provides a comprehensive introduction to feature engineering, including feature generation, feature extraction, feature transformation, feature selection, and feature analysis and evaluation.</p>

			<p>The book presents key concepts, methods, examples, and applications, as well as chapters on feature engineering for major data types such as texts, images, sequences, time series, graphs, streaming data, software engineering data, Twitter data, and social media data. It also contains generic feature generation approaches, as well as methods for generating tried-and-tested, hand-crafted, domain-specific features.</p>
			
			<p>The first chapter defines the concepts of features and feature engineering, offers an overview of the book, and provides pointers to topics not covered in this book. The next six chapters are devoted to feature engineering, including feature generation for specific data types. The subsequent four chapters cover generic approaches for feature engineering, namely feature selection, feature transformation based feature engineering, deep learning based feature engineering, and pattern based feature generation and engineering. The last three chapters discuss feature engineering for social bot detection, software management, and Twitter-based applications respectively.</p>
			
			<p>This book can be used as a reference for data analysts, big data scientists, data preprocessing workers, project managers, project developers, prediction modelers, professors, researchers, graduate students, and upper level undergraduate students. It can also be used as the primary text for courses on feature engineering, or as a supplement for courses on machine learning, data mining, and big data analytics.</p>
	</div>
</div>


<!-- PhD Thesis -->		

<div class="item mix thesis" data-year="2017">
	<div class="pubmain">
	<div class="pubassets">
	
	<a href="#" class="pubcollapse">
	<i class="icon-plus"></i>
	</a>

	<a href="https://repository.asu.edu/items/46233" class="tooltips" title="External link" target="_blank">
	<i class="icon-external-link"></i>
	</a>
	
	<a href="{{ site.url }}/publications/2017/dissertation.pdf" class="tooltips" title="Download" target="_blank">
	<i class="icon-cloud-download"></i>
	</a>
	
	
	<a href="{{ site.url }}/publications/2017/bib/dissertation.bib" class="tooltips" title="Bibtex" target="_blank">
	<i class="icon-book"></i>
	</a>
	
	
	
	</div>
	2017
	<h4 class="pubtitle">Novel image representations and learning taks.</h4>
	<div class="pubauthor"><strong>Ragav Venkatesan</strong></div>
	<div class="pubcite"><span class="label  label-primary">Doctoral Dissertation</span>Doctoral Dissertation, Arizona State University, Tempe 2017. </div>
	
	</div>
	<div class="pubdetails">
	<h4>Abstract</h4>
	<p>Computer Vision as a field has gone through significant changes in the last decade.
	The field has seen tremendous success in designing learning systems with hand-crafted features and in using representation learning to extract better features.
	In this dissertation some novel approaches to representation learning and task learning are studied.
	Multiple-instance learning which is generalization of supervised learning, is one example of task learning that is discussed. 
	In particular, a novel non-parametric $k$-NN-based multiple-instance learning is proposed, which is shown to outperform other existing approaches.
	This solution is applied to a diabetic retinopathy pathology detection problem effectively.</p>
	
	<p>In cases of representation learning, generality of neural features are investigated first.
	This investigation leads to some critical understanding and results in feature generality among datasets.
	The possibility of learning from a mentor network instead of from labels is then investigated.
	Distillation of dark knowledge is used to efficiently mentor a small network from a pre-trained large mentor network.
	These studies help in understanding representation learning with smaller and compressed networks. </p>
	</div>
	</div>
	
	<!-- End of One Item -->


<!-- CNN book -->		

<div class="item mix book" data-year="2017">
	<div class="pubmain">
		<div class="pubassets">
		
			<a href="#" class="pubcollapse">
			<i class="icon-plus"></i>
			</a>
			
			<a href="https://github.com/ragavvenkatesan/Convolutional-Neural-Networks class="tooltips" title="GitHub" target="_blank">
			<i class="icon-code-fork"></i>
			</a>
			
			<a href="https://g.co/kgs/r81Cq8" class="tooltips" title="book website" target="_blank">
			<i class="icon-external-link"></i>
			</a>

			<a href="https://www.amazon.cn/dp/B07LD8Q5YJ" class="tooltips" title="book website" target="_blank">
			<i class="icon-external-link"></i>
			</a>

		</div>
		
		<h4 class="pubtitle"> Convolutional Neural Networks in Visual Computing: A Concise Guide.</h4>
		<h4 class="pubtitle"> 卷积神经网络与视觉计算.</h4>
		<div class="pubauthor"><strong>Ragav Venkatesan</strong>, <a target="_blank" href="http://www.public.asu.edu/~bli24/">Baoxin Li</a></div>
		<div class="pubcite"><span class="label label-primary">Book</span>CRC Press, Tylor and Francis Group, LLC. 2017, 机械工业出版社, LLC. 2019</div>				
	<div class="pubdetails">
		<h4>About the book</h4>
		<p>This book is intented to be a guide for engineers and ML practitioners to effortlessly and in
			a much simpler manner than what a textbook would offer, learn the nuts and bolts of CNNS. We
			target this book for undergraduate students, graduate research students starting off with CNNs
			but mainly industrial practitioners and kagglers. The book is available in English and in Chinese.</p>
		<p>There is a <a target="_blank" href="http://yann.network">
			Toobox</a> associated with this work I developed.
			 associated with this book.</p>
	</div>
</div>
</div>















<!-- SPIE MI 17-->		

<div class="item mix jpaper" data-year="2017">
<div class="pubmain">
<div class="pubassets">

<a href="#" class="pubcollapse">
<i class="icon-plus"></i>
</a>

<a href="https://www.spiedigitallibrary.org/journals/journal-of-medical-imaging/volume-4/issue-03/034003/MIRank-KNN--multiple-instance-retrieval-of-clinically-relevant-diabetic/10.1117/1.JMI.4.3.034003.full" class="tooltips" title="arXiv" target="_blank">
	<i class="icon-external-link"></i>
</a>

<a href="{{ site.url }}/projects/mil.html" class="tooltips" title="Project Page" target="_blank">
<i class="icon-info"></i>
</a>

<a href="{{ site.url }}/publications/2017/bib/mirank_spie_17.bib" class="tooltips" title="Bibtex" target="_blank">
<i class="icon-book"></i>
</a>

</div>
SPIE-MI 2017
<h4 class="pubtitle">MIRank-KNN: Multiple Instance Retrieval of
Clinically-Relevant Diabetic Retinopathy Images</h4>
<div class="pubauthor">Parag Shridhar Chandakkar, <strong>Ragav Venkatesan</strong>, <a traget="_blank" href="http://www.public.asu.edu/~bli24/">Baoxin Li</a></div>
<div class="pubcite"><span class="label label-success">Journal Papers</span>SPIE Journal of Medical Imaging, 2017.</div>

</div>
<div class="pubdetails">
<h4>Abstract</h4>
<p>Diabetic retinopathy (DR) is a consequence of diabetes
and is the leading cause of blindness among working adults.
Regular screening is critical to early detection and treatment of
DR. Computer-aided diagnosis has the potential of improving
the practice in DR screening or diagnosis. This paper presents
an automated approach to retrieving clinically-relevant images
from a set of previously-diagnosed fundus camera images for
improving the efficiency of screening and diagnosis of DR.
Considering that DR lesions are often localized, we propose a
multi-class multiple-instance framework for the retrieval task.
Considering the special visual properties of DR images, we
develop a feature space of a modified color correlogram appended
with statistics of steerable Gaussian filter responses selected by
fast symmetric radial transform points. Experiments with real
DR images demonstrate that the proposed approach is able to
outperform existing methods.</p></div>
</div>

<!-- End of One Item -->


















<!-- arXiv 17-->		

<div class="item mix arxiv" data-year="2017">
<div class="pubmain">
<div class="pubassets">

<a href="#" class="pubcollapse">
<i class="icon-plus"></i>
</a>

<a href="https://arxiv.org/abs/1705.00744" class="tooltips" title="arXiv" target="_blank">
<i class="icon-external-link"></i>
</a>

<a href="https://github.com/ragavvenkatesan/Incremental-GAN" class="tooltips" title="GitHub" target="_blank">
<i class="icon-code-fork"></i>
</a>

<a href="{{ site.url }}/publications/2017/bib/incremental_arxiv_17.bib" class="tooltips" title="Bibtex" target="_blank">
<i class="icon-book"></i>
</a>

</div>
arXiv 2017
<h4 class="pubtitle">A strategy for an uncompromising incremental learner</h4>
<div class="pubauthor"><strong>Ragav Venkatesan</strong>, <a traget="_blank" href="https://cubic.asu.edu/content/hemanth-venkateswara">Hemanth Venkateswara</a>, <a traget="_blank" href="https://cubic.asu.edu/content/dr-sethuraman-panch-panchanathan">Sethuraman Panchanathan</a>, <a traget="_blank" href="http://www.public.asu.edu/~bli24/">Baoxin Li</a></div>
<div class="pubcite"><span class="label label-warning">arXiv Papers</span>arXiv:1705.00744 2017.</div>

</div>
<div class="pubdetails">
<h4>Abstract</h4>
<p>Multi-class supervised learning systems require the knowledge of the entire range of labels they predict. Often when learnt incrementally, they suffer from catastrophic forgetting. To avoid this, generous leeways have to be made to the philosophy of incremental learning that either forces a part of the machine to not learn, or to retrain the machine again with a selection of the historic data. While these tricks work to various degrees, they do not adhere to the spirit of incremental learning. In this article, we redefine incremental learning with stringent conditions that do not allow for any undesirable relaxations and assumptions. We design a strategy involving generative models and the distillation of dark knowledge as a means of hallucinating data along with appropriate targets from past distributions. We call this technique phantom sampling. We show that phantom sampling helps avoid catastrophic forgetting during incremental learning. Using an implementation based on deep neural networks, we demonstrate that phantom sampling dramatically avoids catastrophic forgetting. We apply these strategies to competitive multi-class incremental learning of deep neural networks. Using various benchmark datasets through our strategy, we demonstrate that strict incremental learning could be achieved.</p></div>
</div>

<!-- End of One Item -->

























<!-- arXiv 16-->		

<div class="item mix arxiv" data-year="2016">
<div class="pubmain">
<div class="pubassets">

<a href="#" class="pubcollapse">
<i class="icon-plus"></i>
</a>

<a href="http://arxiv.org/abs/1604.08220" class="tooltips" title="arXiv" target="_blank">
<i class="icon-external-link"></i>
</a>

<a href="https://github.com/ragavvenkatesan/regularizer-network" class="tooltips" title="GitHub" target="_blank">
<i class="icon-code-fork"></i>
</a>

<a href="{{ site.url }}/publications/2016/bib/mentornet_arxiv_16.bib" class="tooltips" title="Bibtex" target="_blank">
<i class="icon-book"></i>
</a>

</div>
arXiv 2016
<h4 class="pubtitle">Diving deeper into mentee networks.</h4>
<div class="pubauthor"><strong>Ragav Venkatesan</strong>, <a traget="_blank" href="http://www.public.asu.edu/~bli24/">Baoxin Li</a></div>
<div class="pubcite"><span class="label label-warning">arXiv Papers</span>arXiv:1604.08220 2016.</div>

</div>
<div class="pubdetails">
<h4>Abstract</h4>
<p>Modern computer vision is all about the possession of powerful image representations. Deeper and deeper convolutional neural networks have been built using larger and larger datasets and are made publicly available. A large swath of computer vision scientists use these pre-trained networks with varying degrees of successes in various tasks. Even though there is tremendous success in copying these networks, the representational space is not learnt from the target dataset in a traditional manner. One of the reasons for opting to use a pre-trained network over a network learnt from scratch is that small datasets provide less supervision and require meticulous regularization, smaller and careful tweaking of learning rates to even achieve stable learning without weight explosion. It is often the case that large deep networks are not portable, which necessitates the ability to learn mid-sized networks from scratch.</p>

<p>In this article, we dive deeper into training these mid-sized networks on small datasets from scratch by drawing additional supervision from a large pre-trained network. Such learning also provides better generalization accuracies than networks trained with common regularization techniques such as l2, l1 and dropouts. We show that features learnt thus, are more general than those learnt independently. We studied various characteristics of such networks and found some interesting behaviors. </p>
</div>
</div>

<!-- End of One Item -->




















<!-- ICIP 16-->		

<div class="item mix cpaper" data-year="2016">
<div class="pubmain">
<div class="pubassets">

<a href="#" class="pubcollapse">
<i class="icon-plus"></i>
</a>

<a href="http://arxiv.org/abs/1605.04369" class="tooltips" title="Long arXiv version" target="_blank">
<i class="icon-external-link"></i>
</a>

<a href="{{ site.url }}/publications/2016/icip_16_ppt.pdf" class="tooltips" title="Slides" target="_blank">
<i class="icon-bar-chart"></i>
</a>

<a href="http://ieeexplore.ieee.org/document/7532315/" class="tooltips" title="IEEE Xplore version" target="_blank">
<i class="icon-external-link"></i>
</a>

<a href="https://github.com/ragavvenkatesan/generality" class="tooltips" title="GitHub" target="_blank">
<i class="icon-code-fork"></i>
</a>

<a href="{{ site.url }}/publications/2016/bib/generality_arxiv_16.bib" class="tooltips" title="Bibtex" target="_blank">
<i class="icon-book"></i>
</a>

</div>
ICIP 2016 / arXiv 2016
<h4 class="pubtitle">On the generality of neural image features.</h4>
<div class="pubauthor"><strong>Ragav Venkatesan</strong>, Jaya Vijetha Gattupalli, <a traget="_blank" href="http://www.public.asu.edu/~bli24/">Baoxin Li</a></div>
<div class="pubcite"><span class="label label-warning">Conference Papers</span>IEEE International Conference on Image Processing, Phoenix, Arizona, USA, 2016. [ORAL]</div>

</div>
<div class="pubdetails">
<h4>Abstract</h4>
<p>Often the filters learned by Convolutional Neural Networks
(CNNs) from different image datasets appear similar.
This similarity of filters is often exploited for the purposes of
transfer learning. This is also being used as an initialization
technique for different tasks in the same dataset or for the
same task in similar datasets. Off-the-shelf CNN features
have capitalized on this idea to promote their networks as
best transferable and most general and are used in a cavalier
manner in day-to-day computer vision tasks.</p>

<p>It is curious that while the filters learned by these CNNs
are related to the atomic structures of the images from which
they are learnt, all datasets learn similar looking low-level filters.
With the understanding that a dataset that contains many
such atomic structures learn general filters and are therefore
useful to initialize other networks with, we propose a way
to analyse and quantify generality. We applied this metric
on several popular character recognition, natural image and
a medical image dataset, and arrive at some interesting conclusions.
On further experimentation we also discovered that
particular classes in a dataset themselves are more general
than others.</p>
</div>
</div>

<!-- End of One Item -->

























<!-- arXiv 15-->		

<div class="item mix arxiv" data-year="2015">
<div class="pubmain">
<div class="pubassets">

<a href="#" class="pubcollapse">
<i class="icon-plus"></i>
</a>


<a href="http://arxiv.org/abs/1512.01174" class="tooltips" title="arXiv" target="_blank">
<i class="icon-external-link"></i>
</a>

<a href="{{ site.url }}/publications/2015/bib/fashion_arxiv_15.bib" class="tooltips" title="Bibtex" target="_blank">
<i class="icon-book"></i>
</a>

</div>
arXiv 2015
<h4 class="pubtitle">Evolution of fashion brands on Twitter and Instagram.</h4>
<div class="pubauthor"><a traget="_blank" href="http://www.public.asu.edu/~lmanikon">Lydia Manikonda</a>, <strong>Ragav Venkatesan</strong>, <a traget="_blank" href="http://rakaposhi.eas.asu.edu/">Subbarao Khambampati</a> and <a traget="_blank" href="http://www.public.asu.edu/~bli24/">Baoxin Li</a></div>
<div class="pubcite"><span class="label label-warning">arXiv Papers</span>arXiv:1512.01174 2015.</div>

</div>
<div class="pubdetails">
<h4>Abstract</h4>
<p>Social media platforms are popular venues for fashion brand marketing and advertising. With the introduction of native advertising, users don't have to endure banner ads that hold very little saliency and are unattractive. Using images and subtle text overlays, even in a world of ever-depreciating attention span, brands can retain their audience and have a capacious creative potential. While an assortment of marketing strategies are conjectured, the subtle distinctions between various types of marketing strategies remain under-explored. This paper presents a qualitative analysis on the influence of social media platforms on different behaviors of fashion brand marketing. We employ both linguistic and computer vision techniques while comparing and contrasting strategic idiosyncrasies. We also analyze brand audience retention and social engagement hence providing suggestions in adapting advertising and marketing strategies over Twitter and Instagram.  </p>
</div>
</div>

<!-- End of One Item -->





































<!-- ICCV 15-->		

<div class="item mix cpaper" data-year="2015">
<div class="pubmain">
<div class="pubassets">

<a href="#" class="pubcollapse">
<i class="icon-plus"></i>
</a>

<a href="http://www.cv-foundation.org/openaccess/content_iccv_2015/html/Venkatesan_Simpler_Non-Parametric_Methods_ICCV_2015_paper.html" class="tooltips" title="CVF version" target="_blank">
<i class="icon-external-link"></i>
</a>

<a href="{{ site.url }}/publications/2015/iccv_15.pdf" class="tooltips" title="Download Longer Version" target="_blank">
<div class="icon-cloud-download"></div>
</a>

<a href="{{ site.url }}/publications/2015/bib/iccv_15.bib" class="tooltips" title="Bibtex" target="_blank">
<i class="icon-book"></i>
</a>

<a href="{{ site.url }}/publications/2015/iccv_15_poster.pdf" class="tooltips" title="Poster" target="_blank">
<i class="icon-picture"></i>
</a>

<a href="https://github.com/ragavvenkatesan/np-mil" class="tooltips" title="GitHub" target="_blank">
<i class="icon-code-fork"></i>

<a href="{{ site.url }}/projects/mil.html" class="tooltips" title="Project Page" target="_blank">
<i class="icon-info"></i>
</a>


</div>
ICCV 2015
<h4 class="pubtitle">Simpler non-parametric methods provide as good or better results to
multiple-instance learning.</h4>
<div class="pubauthor"><strong>Ragav Venkatesan</strong>, Parag Shridhar Chandakkar, <a traget="_blank" href="http://www.public.asu.edu/~bli24/">Baoxin Li</a></div>
<div class="pubcite"><span class="label label-warning">Conference Papers</span>IEEE International Conference on Computer Vision, Santiago, Chile, 2015. [Poster]</div>

</div>
<div class="pubdetails">
<h4>Abstract</h4>
<p>Multiple-instance learning (MIL) is a unique learning
problem in which training data labels are available only for
collections of objects (called bags) instead of individual objects
(called instances). A plethora of approaches have been
developed to solve this problem in the past years. Popular
methods include the diverse density, MILIS and DD-SVM.
While having been widely used, these methods, particularly
those in computer vision have attempted fairly sophisticated
solutions to solve certain unique and particular configurations
of the MIL space.</p>
<p>In this paper, we analyze the MIL feature space using
modified versions of traditional non-parametric techniques
like the Parzen window and k-nearest-neighbour, and develop
a learning approach employing distances to k-nearest
neighbours of a point in the feature space. We show that
these methods work as well, if not better than most recently
published methods on benchmark datasets. We compare
and contrast our analysis with the well-established diversedensity
approach and its variants in recent literature, using
benchmark datasets including the Musk, Andrews’ and
Corel datasets, along with a diabetic retinopathy pathology
diagnosis dataset. Experimental results demonstrate that,
while enjoying an intuitive interpretation and supporting
fast learning, these method have the potential of delivering
improved performance even for complex data arising from
real-world applications.</p>
</div>
</div>

<!-- End of One Item -->
















<!-- SPIE JEI 15-->		

<div class="item mix jpaper" data-year="2015">
<div class="pubmain">
<div class="pubassets">

<a href="#" class="pubcollapse">
<i class="icon-plus"></i>
</a>
<a href="http://electronicimaging.spiedigitallibrary.org/article.aspx?articleid=2213831" class="tooltips" title="External link" target="_blank">
<i class="icon-external-link"></i>
</a>

<a href="{{ site.url }}/publications/2015/bib/jei_15.bib" class="tooltips" title="Bibtex" target="_blank">
<i class="icon-book"></i>
</a>


</div>
JEI 2015
<h4 class="pubtitle">Spatio-temporal video deinterlacing using control grid interpolation</h4>
<div class="pubauthor"><strong>Ragav Venkatesan</strong>, <a target="_blank" href="https://www.linkedin.com/pub/christine-zwart/51/9B4/665">Christine Zwart</a>, <a target="_blank" href="http://ipalab.fulton.asu.edu/people/principal-investigator/" >David Frakes</a>, <a traget="_blank" href="http://www.public.asu.edu/~bli24/">Baoxin Li</a></div>
<div class="pubcite"><span class="label label-success">Journal Papers</span>SPIE Journal of Electronic Imaging, 2015.</div>

</div>
<div class="pubdetails">
<h4>Abstract</h4>
<p>With the advent of progressive format display and broadcast technologies, video deinterlacing has become
an important video processing technique. Numerous approaches exist in literature to accomplish deinterlacing. While
most earlier methods were simple linear filtering-based approaches, the emergence of faster computing technologies
and even dedicated video processing hardware in display units has allowed higher quality, but also more computationally
intense, deinterlacing algorithms to become practical. Most modern approaches analyze motion and content in
video to select different deinterlacing methods for various spatiotemporal regions. In this paper, we introduce a family
of deinterlacers that employs spectral residue to choose between and weight control grid interpolation based spatial
and temporal deinterlacing methods. The proposed approaches perform better than the prior state-of-the-art based on
peak signal-to-noise ratio (PSNR), other visual quality metrics, and simple perception-based subjective evaluations
conducted by human viewers. We further study the advantages of using soft and hard decision thresholds on th visual
performance.</p>
</div>
</div>

<!-- End of One Item -->





















<!-- ISVC 14 -->		

<div class="item mix cpaper" data-year="2014">
<div class="pubmain">
<div class="pubassets">

<a href="#" class="pubcollapse">
<i class="icon-plus"></i>
</a>
<a href="http://www.springerprofessional.de/069---video-based-self-positioning-for-intelligent-transportation-systems-applications/5478188.html" class="tooltips" title="External link" target="_blank">
<i class="icon-external-link"></i>
</a>


<a href="{{ site.url }}/publications/2014/bib/isvc_14.bib" class="tooltips" title="Bibtex" target="_blank">
<i class="icon-book"></i>
</a>


</div>
ISVC 2014
<h4 class="pubtitle">Video-Based Self-Positioning for Intelligent Transport Systems Applications</h4>
<div class="pubauthor"> <a target="_blank" href="https://www.linkedin.com/in/paragchandakkar">Parag Sridhar Chandakkar</a>, <strong>Ragav Venkatesan</strong>, <a traget="_blank" href="http://www.public.asu.edu/~bli24/">Baoxin Li</a></div>
<div class="pubcite"><span class="label label-warning">Conference Papers</span> International Symposium on Visual Computing, Las Vegas, USA, 2014. [ORAL]</div>

</div>
<div class="pubdetails">
<h4>Abstract</h4>
<p>Many urban areas face traffic congestion. Automatic traffic management systems and congestion pricing are getting prominence in recent research. An important stage in such systems is lane prediction and on-road self-positioning. We introduce a novel problem of vehicle self-positioning which involves predicting the number of lanes on the road and localizing the vehicle within those lanes,using the video captured by a dashboard camera. To overcome the disadvantages of most existing low-level vision-based techniques while tackling this complex problem, we formulate a model in which the video is a key observation. The model consists of the number of lanes and vehicle position in those lanes as parameters, hence allowing the use of high-level semantic knowledge. Under this formulation, we employ a lane-width-based model and a maximum-likelihood-estimator making the method tolerant to slight viewing angle variation. The overall approach is tested on real-world videos and is found to be effective.</p>
</div>
</div>

<!-- End of One Item -->
















<!-- VPQM 14 -->		

<div class="item mix cpaper" data-year="2014">
<div class="pubmain">
<div class="pubassets">

<a href="#" class="pubcollapse">
<i class="icon-plus"></i>
</a>
<a href="http://enpub.fulton.asu.edu/resp/vpqm/vpqm14/VPQM2014_Technical_Program_post.pdf" class="tooltips" title="External link" target="_blank">
<i class="icon-external-link"></i>
</a>

<a href="{{ site.url }}/publications/2014/vpqm_14.pdf" class="tooltips" title="Download" target="_blank">
<i class="icon-cloud-download"></i>
</a>


<a href="{{ site.url }}/publications/2014/bib/vpqm_14.bib" class="tooltips" title="Bibtex" target="_blank">
<i class="icon-book"></i>
</a>

<a href="{{ site.url }}/publications/2014/vpqm_14_ppt.pdf" class="tooltips" title="Slides" target="_blank">
<i class="icon-bar-chart"></i>
</a>


</div>
VPQM 2014
<h4 class="pubtitle">Perception-Inspired Spatio-Temporal Video Deinterlacing</h4>
<div class="pubauthor"> <strong>Ragav Venkatesan</strong>, <a target="_blank" href="https://www.linkedin.com/pub/christine-zwart/51/9B4/665">Christine Zwart</a>, <a traget="_blank" href="http://www.public.asu.edu/~bli24/">Baoxin Li</a>, <a target="_blank" href="http://ipalab.fulton.asu.edu/people/principal-investigator/" >David Frakes</a></div>
<div class="pubcite"><span class="label label-warning">Conference Papers</span>International Workshop on Video Processing and Quality Metrics for Consumer Electronics, Phoenix, USA , 2014 [ORAL]</div>

</div>
<div class="pubdetails">
<h4>Abstract</h4>
<p>With the advent of progressive format display and broadcast technologies, video deinterlacing has become an important video processing technique. Numerous approaches exist in literature to accomplish deinterlacing. While
most earlier methods were simple linear filtering-based approaches, the emergence of faster computing technologies
and even dedicated video processing hardware in display units has allowed higher quality, but also more computationally
intense, deinterlacing algorithms to become practical. Most modern approaches analyze motion and content in
video to select different deinterlacing methods for various spatiotemporal regions. In this paper, we introduce a family
of deinterlacers that employs spectral residue to choose between and weight control grid interpolation based spatial
and temporal deinterlacing methods. The proposed approaches perform better than the prior state-of-the-art based on
peak signal-to-noise ratio (PSNR), other visual quality metrics, and simple perception-based subjective evaluations
conducted by human viewers. We further study the advantages of using soft and hard decision thresholds on th visual
performance.</p>
</div>
</div>

<!-- End of One Item -->













<!-- SPIE MI 13 -->		

<div class="item mix cpaper" data-year="2013">
<div class="pubmain">
<div class="pubassets">

<a href="#" class="pubcollapse">
<i class="icon-plus"></i>
</a>
<a href="http://proceedings.spiedigitallibrary.org/proceeding.aspx?articleid=1658260" class="tooltips" title="External link" target="_blank">
<i class="icon-external-link"></i>
</a>


<a href="{{ site.url }}/publications/2013/bib/spie_13.bib" class="tooltips" title="Bibtex" target="_blank">
<i class="icon-book"></i>
</a>

<a href="{{ site.url }}/publications/2013/spie_13_ppt.pdf" class="tooltips" title="Slides" target="_blank">
<i class="icon-bar-chart"></i>
</a>

<a href="{{ site.url }}/projects/mil.html" class="tooltips" title="Project Page" target="_blank">
<i class="icon-info"></i>
</a> 

</div>
SPIE-MI 2013
<h4 class="pubtitle">Retrieving clinically relevant diabetic retinopathy images using a multi-class multiple-instance framework</h4>
<div class="pubauthor"> <a target="_blank" href="https://www.linkedin.com/in/paragchandakkar">Parag Sridhar Chandakkar</a>, <strong>Ragav Venkatesan</strong>,  <a target="_blank" href="http://www.public.asu.edu/~bli24/" >Baoxin Li</a>, Helen Li</div>
<div class="pubcite"><span class="label label-warning">Conference Papers</span>SPIE conference on Medical Imaging, Florida, USA, 2013. [ORAL]</div>

</div>
<div class="pubdetails">
<h4>Abstract</h4>
<p>Diabetic retinopathy (DR) is a vision
-
threatening complication that arises due to prolo
nged presenc
e of diabetes. When
detected and diagnosed at early stages, the effect of DR on vision can be greatly reduced
. Content
-
based image retrieval
can be employed to provide a clinician with instant references to archival and standardized images that are clinica
lly
relevant to the image under diagnosis. This is an innovative way of utilizing the vast expert knowledge hidden in
archives of previously diagnosed fundus camera images that helps an ophthalmologist in improving the performance of
diagnosis. In this pap
er, with a focus on two significant DR clinical findings, namely, microaneurysm and
neovascularization
that are representative symptoms of non
-
proliferate and proliferate diabetic retinopathy
, the authors
propose a multi
-
class multiple
-
instance image retri
eval framework that makes use of a modified color correlogram and
statistics of steerable Gaussian Filter responses for retrieving clinically relevant images from a database. Experiments are
performed using fundus camera images and the results compared wit
h other prior
art methods demonstrate the improved
performance of the proposed approach. </p>
</div>
</div>

<!-- End of One Item -->
















<!-- SPIE JEI 12 -->		

<div class="item mix jpaper" data-year="2012">
<div class="pubmain">
<div class="pubassets">

<a href="#" class="pubcollapse">
<i class="icon-plus"></i>
</a>
<a href="http://electronicimaging.spiedigitallibrary.org/article.aspx?articleid=1392284" class="tooltips" title="External link" target="_blank">
<i class="icon-external-link"></i>
</a>															                                                            


<a href="{{ site.url }}/publications/2012/bib/jei_12.bib" class="tooltips" title="Bibtex" target="_blank">
<i class="icon-book"></i>
</a>


</div>
JEI 2012
<h4 class="pubtitle">Decomposed Multidimensional Control Grid Interpolation for Common Interpolation-Based Image Processing Applications in Consumer Electronics</h4>
<div class="pubauthor"><a target="_blank" href="https://www.linkedin.com/pub/christine-zwart/51/9B4/665">Christine Zwart</a>, <strong>Ragav Venkatesan</strong>, <a target="_blank" href="http://ipalab.fulton.asu.edu/people/principal-investigator/" >David Frakes</a></div>
<div class="pubcite"><span class="label  label-success">Journal Papers</span>SPIE Journal of Electronic Imaging,  2012.</div>

</div>
<div class="pubdetails">
<h4>Abstract</h4>
<p>Interpolation is an essential and broadly employed function
of signal processing. Accordingly, considerable development has
focused on advancing interpolation algorithms toward optimal accuracy. Such development has motivated a clear shift in the state-of-the
art from classical interpolation to more intelligent and resourceful
approaches, registration-based interpolation for example.As a natural
result, many of the most accurate current algorithms are highly complex, specific, and computationally demanding. However, the diverse
hardware destinations for interpolation algorithms present unique
constraints that often preclude use of the most accurate available
options. For example, while computationally demanding interpolators
may be suitable for highly equipped image processing platforms (e.g.,
computer workstations and clusters), only more efficient interpolators
may be practical for less well equipped platforms (e.g., smartphones
and tablet computers). The latter examples of consumer electronics
present a design tradeoff in this regard: high accuracy interpolation
benefits the consumer experience but computing capabilities are
limited. It follows that interpolators with favorable combinations of
accuracy and efficiency are of great practical value to the consumer
electronics industry. We address multidimensional interpolation-based
image processing problems that are common to consumer electronic
devices through a decomposition approach. The multidimensional
problems are first broken down into multiple, independent, one-
dimensional (1-D) interpolation steps that are then executed with a
newly modifiedregistration-based one-dimensional controlgrid interpolator. The proposed approach, decomposed multidimensional control
grid interpolation (DMCGI), combines the accuracy of registrationbased interpolation with the simplicity, flexibility, and computational efficiency of a 1-D interpolation framework. Results demonstrate
that DMCGI provides improved interpolation accuracy (and other benefits) in image resizing, color sample demosaicing, and video deinterlacing applications, at a computational cost that is manageable or
reduced in comparison to popular alternatives.</p>
</div>
</div>

<!-- End of One Item -->




















<!-- ACM BCB 12 -->		

<div class="item mix poster" data-year="2012">
<div class="pubmain">
<div class="pubassets">

<a href="#" class="pubcollapse">
<i class="icon-plus"></i>
</a>
<a href="http://dl.acm.org/citation.cfm?id=2383030" class="tooltips" title="External link" target="_blank">
<i class="icon-external-link"></i>
</a>


<a href="{{ site.url }}/publications/2012/bib/bcb_12.bib" class="tooltips" title="Bibtex" target="_blank">
<i class="icon-book"></i>
</a>


<a href="{{ site.url }}/publications/2012/bcb_12_poster.pdf" class="tooltips" title="Poster" target="_blank">
<i class="icon-picture"></i>
</a>


<a href="{{ site.url }}/projects/mil.html" class="tooltips" title="Project Page" target="_blank">
<i class="icon-info"></i>
</a>

</div>
ACM-BCB 2012
<h4 class="pubtitle">Clinically Relevant Diabetic Retinopathy Image Retrieval Using a Multi-Class Multiple Instance Framework</h4>
<div class="pubauthor"><a target="_blank" href="https://www.linkedin.com/in/paragchandakkar">Parag Sridhar Chandakkar</a>, <strong>Ragav Venkatesan</strong>,  <a target="_blank" href="http://www.public.asu.edu/~bli24/" >Baoxin Li</a>, Helen Li</div>
<div class="pubcite"><span class="label  label-warning">Poster Papers</span>ACM conference on Bio-informatics, Computational Biology and Biomedicine, Florida, USA, 2012. [Poster]</div>

</div>
<div class="pubdetails">
<h4>Abstract</h4>
<p>Diabetic retinopathy (DR) is a vision-threatening complication that affects people suffering from diabetes. Diagnosis of DR during early stages can significantly reduce the risk of severe vision loss. The process of DR severity grading is prone to human error and it also depends on the expertise of the ophthalmologist. As a result, many researchers have started exploring automated detection and evaluation of diabetic retinal lesions. Unfortunately, to date there is no automated system that can perform DR lesion detection with the accuracy that is comparable to a human expert. In this poster, we present a novel way of employing content-based image retrieval for providing a clinician with instant reference to archival and standardized DR images that are used for assisting the ophthalmologist with the diagnosis of a given DR image. The focus of the poster is on retrieving DR images with two significant DR clinical findings, namely, microaneurysm (MA) and neovascularization (NV). We propose a multi-class multiple-instance DR image retrieval framework that makes use of a modified color correlogram (CC) and statistics of steerable Gaussian filter (SGF) responses. Experiments using real DR images with comparisons to other prior-art methods demonstrate
the improved performance of the proposed approach. </p>
</div>
</div>

<!-- End of One Item -->


















<!-- IEEE EMBC 12  -->		

<div class="item mix cpaper" data-year="2012">
<div class="pubmain">
<div class="pubassets">

<a href="#" class="pubcollapse">
<i class="icon-plus"></i>
</a>
<a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6346216" class="tooltips" title="External link" target="_blank">
<i class="icon-external-link"></i>
</a>


<a href="{{ site.url }}/publications/2012/bib/embc_12.bib" class="tooltips" title="Bibtex" target="_blank">
<i class="icon-book"></i>
</a>


<a href="{{ site.url }}/publications/2012/embc_12_poster.pdf" class="tooltips" title="Poster" target="_blank">
<i class="icon-picture"></i>
</a>

<a href="{{ site.url }}/projects/mil.html" class="tooltips" title="Project Page" target="_blank">
<i class="icon-info"></i>
</a>

</div>
EMBC 2012
<h4 class="pubtitle">Classification of Diabetic Retinopathy Images Using Multi-Class Multiple-Instance Learning Based on Color Correlogram Features</h4>
<div class="pubauthor"><strong>Ragav Venkatesan</strong>, <a target="_blank" href="https://www.linkedin.com/in/paragchandakkar">Parag Sridhar Chandakkar</a>,  <a target="_blank" href="http://www.public.asu.edu/~bli24/" >Baoxin Li</a>, Helen Li</div>
<div class="pubcite"><span class="label  label-warning">Conference Papers</span>IEEE International Conference Engineering in Medicine and Biology Society, San Diego, USA, 2012. [Poster]</div>

</div>
<div class="pubdetails">
<h4>Abstract</h4>
<p>All people with diabetes have the risk of developing diabetic retinopathy (DR), a vision-threatening complication. Early detection and timely treatment can reduce the occurrence of blindness due to DR. Computer-aided diagnosis has the potential benefit of improving the accuracy and speed in DR detection. This study is concerned with automatic classification of images with microaneurysm (MA) and neovascularization (NV), two important DR clinical findings. Together with normal images, this presents a 3-class classification problem. We propose a modified color auto-correlogram feature (AutoCC) with low dimensionality that is spectrally tuned towards DR images. Recognizing the fact that the images with or without MA or NV are generally different only in small, localized regions, we propose to employ a multi-class, multiple-instance learning framework for performing the classification task using the proposed feature. Extensive experiments including comparison with a few state-of-art image classification approaches have been performed and the results suggest that the proposed approach is promising as it outperforms other methods by a large margin.</p>
</div>
</div>

<!-- End of One Item -->

















<!-- ICIP 12  -->		

<div class="item mix cpaper" data-year="2012">
<div class="pubmain">
<div class="pubassets">

<a href="#" class="pubcollapse">
<i class="icon-plus"></i>
</a>
<a href="http://ieeexplore.ieee.org/xpl/articleDetails.jsp?arnumber=6466996" class="tooltips" title="External link" target="_blank">
<i class="icon-external-link"></i>
</a>


<a href="{{ site.url }}/publications/2012/bib/icip_12.bib" class="tooltips" title="Bibtex" target="_blank">
<i class="icon-book"></i>
</a>


<a href="{{ site.url }}/publications/2012/icip_12_poster.pdf" class="tooltips" title="Poster" target="_blank">
<i class="icon-picture"></i>
</a>


</div>
ICIP 2012
<h4 class="pubtitle">Video deinterlacing with control grid interpolation </h4>
<div class="pubauthor"><strong>Ragav Venkatesan</strong>, <a target="_blank" href="https://www.linkedin.com/pub/christine-zwart/51/9B4/665">Christine Zwart</a>, <a target="_blank" href="http://ipalab.fulton.asu.edu/people/principal-investigator/" >David Frakes</a></div>
<div class="pubcite"><span class="label  label-warning">Conference Papers</span>IEEE International Conference on Image Processing, Florida, USA, 2012. [Poster]</div>

</div>
<div class="pubdetails">
<h4>Abstract</h4>
<p>Video deinterlacing is a key technique in digital video processing, particularly with the widespread usage of LCD and plasma TVs. This paper proposes a novel spatio-temporal video deinterlacing technique that adaptively chooses between results from segment adaptive gradient angle interpolation (SAGA), vertical temporal filter (VTF) and temporal line averaging (LA). The proposed method performs better than several popular benchmarking methods in terms of both visual quality and PSNR and requires minimal computational overhead. The algorithm performs better than existing approaches on fine moving edges and semi-static regions of videos, which are recognized as
particularly challenging deinterlacing cases. </p>
</div>
</div>

<!-- End of One Item -->

























<!-- MS Thesis -->		

<div class="item mix thesis" data-year="2012">
<div class="pubmain">
<div class="pubassets">

<a href="#" class="pubcollapse">
<i class="icon-plus"></i>
</a>
<a href="http://gradworks.umi.com/15/14/1514997.html" class="tooltips" title="External link" target="_blank">
<i class="icon-external-link"></i>
</a>

<a href="{{ site.url }}/publications/2012/ragav_thesis_12.pdf" class="tooltips" title="Download" target="_blank">
<i class="icon-cloud-download"></i>
</a>


<a href="{{ site.url }}/publications/2012/bib/ragav_thesis_12.bib" class="tooltips" title="Bibtex" target="_blank">
<i class="icon-book"></i>
</a>



</div>
2012
<h4 class="pubtitle">Video Deinterlacing using Control Grid Interpolation Frameworks</h4>
<div class="pubauthor"><strong>Ragav Venkatesan</strong></div>
<div class="pubcite"><span class="label  label-primary">Masters Thesis</span>Masters Thesis, Arizona State University, Tempe 2012. </div>

</div>
<div class="pubdetails">
<h4>Abstract</h4>
<p>Video deinterlacing is a key technique in digital video processing, particularly with the widespread usage of LCD and plasma TVs. This thesis proposes a novel spatio-temporal, non-linear video deinterlacing technique that adaptively chooses between the results from one dimensional control grid interpolation (1DCGI), vertical temporal filter (VTF) and temporal line averaging (LA). The proposed method performs better than several popular benchmarking methods in terms of both visual quality and peak signal to noise ratio (PSNR). The algorithm performs better than existing approaches like edge-based line averaging (ELA) and spatio-temporal edge-based median filtering (STELA) on fine moving edges and semi-static regions of videos, which are recognized as particularly challenging deinterlacing cases. The proposed approach also performs better than the state-of-the-art content adaptive vertical temporal filtering (CAVTF) approach. Along with the main approach several spin-off approaches are also proposed each with its own characteristics </p>
</div>
</div>

<!-- End of One Item -->














<!-- Hindu -->		

<div class="item mix media" data-year="2012">
<div class="pubmain">
<div class="pubassets">

<a href="#" class="pubcollapse">
<i class="icon-plus"></i>
</a>
<a href="http://www.thehindu.com/features/education/issues/academic-dishonesty/article4021902.ece" class="tooltips" title="External link" target="_blank">
<i class="icon-external-link"></i>
</a>

<a href="{{ site.url }}/publications/2012/hindu_12.pdf" class="tooltips" title="Download" target="_blank">
<i class="icon-cloud-download"></i>
</a>

           

</div>
2012
<h4 class="pubtitle">Academic Dishonesty: Why integrity is an important virtue</h4>
<div class="pubauthor"><strong>Ragav Venkatesan</strong></div>
<div class="pubcite"><span class="label  label-primary">Media Articles</span>National Newspaper - The Hindu, Education Plus </div>

</div>
<div class="pubdetails">
<h4>Quote</h4>
<p>Integrity is much like volunteerism, not an act but a virtue. If found guilty, could lead to serious consequences including deportation and retraction of the degree. Most importantly, as men and women of science it is our duty to credit those who deserve. </p>
</div>
</div>													















<!-- Alonso Quixana-->		

<div class="item mix book" data-year="2014">
<div class="pubmain">
<div class="pubassets">

<a href="#" class="pubcollapse">
<i class="icon-plus"></i>
</a>


<a href="{{ site.url }}/publications/2015/alonso.pdf" class="tooltips" title="Download" target="_blank">
<i class="icon-cloud-download"></i>
</a>




</div>

<h4 class="pubtitle">Stuff that no senior would tell you</h4>
<div class="pubauthor"><strong>Alonso Quixana</strong> Pseudonym of Ragav Venkatesan</div>
<div class="pubcite"><span class="label label-primary">Book</span>Self-Published.</div>

</div>
<div class="pubdetails">
<h4>About the book</h4>
<p>This book is a collection of documents that Alonso  wrote and constantly updated since 2011 on online forums. Some of them have also been added on from <a href="https://www.youtube.com/watch?v=KTQ2wrIY4Iw">the hangout with Alonso Quixana</a> series of hangout videos and other conversations that I hosted. These have also been some notes that I made during my time at ASU and some chats and conversations that I have had during the last five years both with students who are new and students who are settled.</p> 

<p>Although this book is written for prospective ASU Indian students, the contents work for international students from any country going to any school in the US. One should use this book as an addition to all the folks they talk with online. I write this book because I find that in every university facebook group, some questions are never asked and even if asked, the answers are not what a responsible senior should give. I write this book also to impart two virtues in students that one might not find in India (or probably other countries).</p>

<ul>
<li> The idea that one can succeed in anything they want to, as long as they work hard. </li>
<li> The idea that one shouldn't compete so hard to be average.</li>
</ul>
<p>Hopefully I will succeed. Please enjoy the book as you would any novel. Please share the book to your friends from your GRE classes or from your college who are attempting to come to the US as well. Since I am self-publishing this version (still working on getting a publisher in India) and I really don't have time for marketing, I am not going to make a big PR push.</p>
</div>
</div>

<!-- Alonso Quixana-->
